{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "view-in-github"
   },
   "source": [
    "<a href=\"https://colab.research.google.com/github/yscope75/CS2225.CH2001020/blob/master/FaceDetectionFromWebCam.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "eHrVGRBRnQXL"
   },
   "outputs": [],
   "source": [
    "# capture image from camera\n",
    "# Copy from https://colab.research.google.com/notebooks/snippets/advanced_outputs.ipynb#scrollTo=2viqYx97hPMi\n",
    "from IPython.display import display, Javascript\n",
    "from google.colab.output import eval_js\n",
    "from base64 import b64decode\n",
    "\n",
    "def take_photo(filename='photo.jpg', quality=0.8):\n",
    "  js = Javascript('''\n",
    "    async function takePhoto(quality) {\n",
    "      const div = document.createElement('div');\n",
    "      const capture = document.createElement('button');\n",
    "      capture.textContent = 'Capture';\n",
    "      div.appendChild(capture);\n",
    "\n",
    "      const video = document.createElement('video');\n",
    "      video.style.display = 'block';\n",
    "      const stream = await navigator.mediaDevices.getUserMedia({video: true});\n",
    "\n",
    "      document.body.appendChild(div);\n",
    "      div.appendChild(video);\n",
    "      video.srcObject = stream;\n",
    "      await video.play();\n",
    "\n",
    "      // Resize the output to fit the video element.\n",
    "      google.colab.output.setIframeHeight(document.documentElement.scrollHeight, true);\n",
    "\n",
    "      // Wait for Capture to be clicked.\n",
    "      await new Promise((resolve) => capture.onclick = resolve);\n",
    "\n",
    "      const canvas = document.createElement('canvas');\n",
    "      canvas.width = video.videoWidth;\n",
    "      canvas.height = video.videoHeight;\n",
    "      canvas.getContext('2d').drawImage(video, 0, 0);\n",
    "      stream.getVideoTracks()[0].stop();\n",
    "      div.remove();\n",
    "      return canvas.toDataURL('image/jpeg', quality);\n",
    "    }\n",
    "    ''')\n",
    "  display(js)\n",
    "  data = eval_js('takePhoto({})'.format(quality))\n",
    "  binary = b64decode(data.split(',')[1])\n",
    "  with open(filename, 'wb') as f:\n",
    "    f.write(binary)\n",
    "  return filename"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Z7m4twOWoShG"
   },
   "outputs": [],
   "source": [
    "# test take_photo function\n",
    "from IPython.display import Image\n",
    "try:\n",
    "  filename = take_photo()\n",
    "  print('Saved to {}'.format(filename))\n",
    "  \n",
    "  # Show the image which was just taken.\n",
    "  display(Image(filename))\n",
    "except Exception as err:\n",
    "  # Errors will be thrown if the user does not have a webcam or if they do not\n",
    "  # grant the page permission to access it.\n",
    "  print(str(err))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "qxvXI6cTon0j"
   },
   "outputs": [],
   "source": [
    "# face recognition function\n",
    "def face_reg(detector, image_path, **kwargs):\n",
    "  \"\"\"\n",
    "    Detect faces inside input image and draw bounding box\n",
    "    \n",
    "    args:\n",
    "      - detector: face detector ( could be cascade if using cascade in opencv, other machine learning models)\n",
    "      - image_path (str): link to image file\n",
    "      - *arg: any parameters for dectector  \n",
    "  \"\"\"\n",
    "    import cv2\n",
    "    if isinstance(detector, cv2.CascadeClassifier):\n",
    "        image = cv2.imread(image_path)\n",
    "        \n",
    "        # create a copy of the image to prevent any changes to the original one.\n",
    "        image_copy = image.copy()\n",
    "        \n",
    "        #convert the test image to gray scale as opencv face detector expects gray images\n",
    "        gray_image = cv2.cvtColor(image_copy, cv2.COLOR_BGR2GRAY)\n",
    "        \n",
    "        # Applying the haar classifier to detect faces\n",
    "        scaleFactor = kwargs['scaleFactor'] if 'scaleFactor' in kwarg else 1.1\n",
    "        minNeighbors = kwargs['minNeighbors'] if 'minNeighbors' in kwarg else 5\n",
    "        faces_rect = cascade.detectMultiScale(gray_image, scaleFactor=scaleFactor, minNeighbors=minNeighbors)\n",
    "        \n",
    "        for (x, y, w, h) in faces_rect:\n",
    "            cv2.rectangle(image_copy, (x, y), (x+w, y+h), (0, 255, 0), 15)\n",
    "        \n",
    "        return image_copy\n",
    "    else:\n",
    "        pass"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "authorship_tag": "ABX9TyOJdBsw05CkaNDdpm5R2G7s",
   "collapsed_sections": [],
   "include_colab_link": true,
   "name": "FaceDetectionFromWebCam.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
