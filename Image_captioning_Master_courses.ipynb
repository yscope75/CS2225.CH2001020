{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Image captioning - Master courses.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyMHb1E6m15YgBlIjxDRPQeL",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "2447374318854f59bfe02420b611b235": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_ce07cbfca2fe484397ee37169875c159",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_7f3f994f763240e68dce49f342d67414",
              "IPY_MODEL_9ed7b239592746b98a94f61066e12c0f"
            ]
          }
        },
        "ce07cbfca2fe484397ee37169875c159": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "7f3f994f763240e68dce49f342d67414": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_1510010d8b1b47169213416deed27963",
            "_dom_classes": [],
            "description": "",
            "_model_name": "FloatProgressModel",
            "bar_style": "info",
            "max": 1,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 1,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_ace4422910994fa98ca59f7bacee1181"
          }
        },
        "9ed7b239592746b98a94f61066e12c0f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_6c074b8e02e7424ab3cf6cab098e67a4",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "â€‹",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 252878848/? [00:20&lt;00:00, 101283776.36it/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_2fc5d785ef7b46eab9d355416fd13ba6"
          }
        },
        "1510010d8b1b47169213416deed27963": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "ace4422910994fa98ca59f7bacee1181": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "6c074b8e02e7424ab3cf6cab098e67a4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "2fc5d785ef7b46eab9d355416fd13ba6": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "f4f714cc904645eaa12af843c6228eea": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_323b9f34428b4715b4850fe2e8743919",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_d60baeb2033440b6b97811945eaec12d",
              "IPY_MODEL_6f561ade3e6f4e53a527c4b417002305"
            ]
          }
        },
        "323b9f34428b4715b4850fe2e8743919": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "d60baeb2033440b6b97811945eaec12d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_094479d44e714ed9a975b175cc48366a",
            "_dom_classes": [],
            "description": "",
            "_model_name": "FloatProgressModel",
            "bar_style": "info",
            "max": 1,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 1,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_faa02b84acca48adb1768474da478d53"
          }
        },
        "6f561ade3e6f4e53a527c4b417002305": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_090276c63d2c4f6bb7fc77e02704ba5e",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "â€‹",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 13510574080/? [03:49&lt;00:00, 76732152.32it/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_4c25f5d0a60745b68c8476b70c04ced2"
          }
        },
        "094479d44e714ed9a975b175cc48366a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "faa02b84acca48adb1768474da478d53": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "090276c63d2c4f6bb7fc77e02704ba5e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "4c25f5d0a60745b68c8476b70c04ced2": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/yscope75/CS2225.CH2001020/blob/master/Image_captioning_Master_courses.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "p8ekI-u73s7H"
      },
      "source": [
        "import torchvision.datasets as dset\r\n",
        "import torchvision.datasets.utils as dset_utils\r\n",
        "import torchvision.transforms as transforms\r\n",
        "import os"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kLRa-KjZE_3W"
      },
      "source": [
        "import torch\r\n",
        "from torch import nn\r\n",
        "import torchvision\r\n",
        "from torchsummary import summary"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 151,
          "referenced_widgets": [
            "2447374318854f59bfe02420b611b235",
            "ce07cbfca2fe484397ee37169875c159",
            "7f3f994f763240e68dce49f342d67414",
            "9ed7b239592746b98a94f61066e12c0f",
            "1510010d8b1b47169213416deed27963",
            "ace4422910994fa98ca59f7bacee1181",
            "6c074b8e02e7424ab3cf6cab098e67a4",
            "2fc5d785ef7b46eab9d355416fd13ba6",
            "f4f714cc904645eaa12af843c6228eea",
            "323b9f34428b4715b4850fe2e8743919",
            "d60baeb2033440b6b97811945eaec12d",
            "6f561ade3e6f4e53a527c4b417002305",
            "094479d44e714ed9a975b175cc48366a",
            "faa02b84acca48adb1768474da478d53",
            "090276c63d2c4f6bb7fc77e02704ba5e",
            "4c25f5d0a60745b68c8476b70c04ced2"
          ]
        },
        "id": "6-WlBcZUGZuc",
        "outputId": "d0556978-b445-4805-85c6-e95b52793032"
      },
      "source": [
        "annotation_folder = os.path.join(os.path.abspath('.') + '/coco/annotations/')\r\n",
        "image_folder = os.path.join(os.path.abspath('.') + '/coco/train2014/')\r\n",
        "# Download and unzip annotations \r\n",
        "dset_utils.download_and_extract_archive(url='http://images.cocodataset.org/annotations/annotations_trainval2014.zip',\r\n",
        "                                        download_root=annotation_folder,\r\n",
        "                                        extract_root=annotation_folder,\r\n",
        "                                        filename='captions.zip')\r\n",
        "# Download and unzion images\r\n",
        "dset_utils.download_and_extract_archive(url='http://images.cocodataset.org/zips/train2014.zip',\r\n",
        "                                        download_root=image_folder,\r\n",
        "                                        extract_root=image_folder,\r\n",
        "                                        filename='train2014.zip')"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading http://images.cocodataset.org/annotations/annotations_trainval2014.zip to /content/coco/annotations/captions.zip\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "2447374318854f59bfe02420b611b235",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=1.0, bar_style='info', max=1.0), HTML(value='')))"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Extracting /content/coco/annotations/captions.zip to /content/coco/annotations/\n",
            "Downloading http://images.cocodataset.org/zips/train2014.zip to /content/coco/train2014/train2014.zip\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "f4f714cc904645eaa12af843c6228eea",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=1.0, bar_style='info', max=1.0), HTML(value='')))"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Extracting /content/coco/train2014/train2014.zip to /content/coco/train2014/\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8kgQnHJVQj7k"
      },
      "source": [
        "# Setup device\r\n",
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wUy74YyzAU7v"
      },
      "source": [
        "# Definition of main model\r\n",
        "# Begin with Encoder\r\n",
        "class Encoder(nn.Module):\r\n",
        "  \"\"\"\r\n",
        "    Encode image input using pre-trained Resnet152 model on imagenet\r\n",
        "  \"\"\"\r\n",
        "  def __init__(self, encoded_size=64):\r\n",
        "    super(Encoder, self).__init__()\r\n",
        "    resnet152 = torchvision.models.resnet152(pretrained=True)\r\n",
        "    # remove the last two layers and keep the last CNN output \r\n",
        "    modules = list(resnet152.children())[:-2] \r\n",
        "    self.res_encoder = nn.Sequential(*modules) # last output (batch_size, 2048, 8, 8)\r\n",
        "    # Flatten feature vector to (batch_size, 2048, 64)\r\n",
        "    self.flat_embed = nn.Flatten(start_dim=2)\r\n",
        "    # normalize variable input size to encoded size using adaptive pooling\r\n",
        "    \r\n",
        "\r\n",
        "  def forward(self, X_in):\r\n",
        "    \"\"\"\r\n",
        "      The forward pass of encoder \r\n",
        "      args:\r\n",
        "      - X_in: input data batch of size (batch, 3, Height, weight)\r\n",
        "      return: encoded images of size (batch, embed_size, 64)\r\n",
        "    \"\"\"\r\n",
        "    e_out = self.res_encoder(X_in) \r\n",
        "    # Flatten output vector to (batch_size, embedding_size, 64)\r\n",
        "    e_out = self.flat_embed(e_out)\r\n",
        "    # Change shape of output encoded to (batch_size, 64, embedding_dim)\r\n",
        "    e_out = e_out.permute(0, 2, 1)\r\n",
        "    return out\r\n",
        "    \r\n",
        "  "
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "g1ZnU43UWZ3c"
      },
      "source": [
        "class BahdanauAttention(nn.Module):\r\n",
        "  \"\"\"\r\n",
        "    Define attention mechanism module on encoded image for genrating text\r\n",
        "  \"\"\"\r\n",
        "  def __init__(self, encoder_dim, decoder_dim):\r\n",
        "    \"\"\"\r\n",
        "      args: \r\n",
        "      - encoder_dim: size of encoded image\r\n",
        "      - decoder_dim: size of encoder \r\n",
        "    \"\"\"\r\n",
        "    super(Attention, self).__init__()\r\n",
        "    self.encoder_att = nn.Linear(encoder_dim, atten_dim)\r\n",
        "    self.decoder_att = nn.Linear(decoder_dim, atten_dim)\r\n",
        "    \r\n",
        "    "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8mMpJfpxQkfK"
      },
      "source": [
        "resent152 = torchvision.models.resnet152(pretrained=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CTYRpTN7ITu5",
        "outputId": "4fc88951-976d-47fe-f14a-7827f2e720e7"
      },
      "source": [
        "summary(resent152, input_size=(3,244,244))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "----------------------------------------------------------------\n",
            "        Layer (type)               Output Shape         Param #\n",
            "================================================================\n",
            "            Conv2d-1         [-1, 64, 122, 122]           9,408\n",
            "       BatchNorm2d-2         [-1, 64, 122, 122]             128\n",
            "              ReLU-3         [-1, 64, 122, 122]               0\n",
            "         MaxPool2d-4           [-1, 64, 61, 61]               0\n",
            "            Conv2d-5           [-1, 64, 61, 61]           4,096\n",
            "       BatchNorm2d-6           [-1, 64, 61, 61]             128\n",
            "              ReLU-7           [-1, 64, 61, 61]               0\n",
            "            Conv2d-8           [-1, 64, 61, 61]          36,864\n",
            "       BatchNorm2d-9           [-1, 64, 61, 61]             128\n",
            "             ReLU-10           [-1, 64, 61, 61]               0\n",
            "           Conv2d-11          [-1, 256, 61, 61]          16,384\n",
            "      BatchNorm2d-12          [-1, 256, 61, 61]             512\n",
            "           Conv2d-13          [-1, 256, 61, 61]          16,384\n",
            "      BatchNorm2d-14          [-1, 256, 61, 61]             512\n",
            "             ReLU-15          [-1, 256, 61, 61]               0\n",
            "       Bottleneck-16          [-1, 256, 61, 61]               0\n",
            "           Conv2d-17           [-1, 64, 61, 61]          16,384\n",
            "      BatchNorm2d-18           [-1, 64, 61, 61]             128\n",
            "             ReLU-19           [-1, 64, 61, 61]               0\n",
            "           Conv2d-20           [-1, 64, 61, 61]          36,864\n",
            "      BatchNorm2d-21           [-1, 64, 61, 61]             128\n",
            "             ReLU-22           [-1, 64, 61, 61]               0\n",
            "           Conv2d-23          [-1, 256, 61, 61]          16,384\n",
            "      BatchNorm2d-24          [-1, 256, 61, 61]             512\n",
            "             ReLU-25          [-1, 256, 61, 61]               0\n",
            "       Bottleneck-26          [-1, 256, 61, 61]               0\n",
            "           Conv2d-27           [-1, 64, 61, 61]          16,384\n",
            "      BatchNorm2d-28           [-1, 64, 61, 61]             128\n",
            "             ReLU-29           [-1, 64, 61, 61]               0\n",
            "           Conv2d-30           [-1, 64, 61, 61]          36,864\n",
            "      BatchNorm2d-31           [-1, 64, 61, 61]             128\n",
            "             ReLU-32           [-1, 64, 61, 61]               0\n",
            "           Conv2d-33          [-1, 256, 61, 61]          16,384\n",
            "      BatchNorm2d-34          [-1, 256, 61, 61]             512\n",
            "             ReLU-35          [-1, 256, 61, 61]               0\n",
            "       Bottleneck-36          [-1, 256, 61, 61]               0\n",
            "           Conv2d-37          [-1, 128, 61, 61]          32,768\n",
            "      BatchNorm2d-38          [-1, 128, 61, 61]             256\n",
            "             ReLU-39          [-1, 128, 61, 61]               0\n",
            "           Conv2d-40          [-1, 128, 31, 31]         147,456\n",
            "      BatchNorm2d-41          [-1, 128, 31, 31]             256\n",
            "             ReLU-42          [-1, 128, 31, 31]               0\n",
            "           Conv2d-43          [-1, 512, 31, 31]          65,536\n",
            "      BatchNorm2d-44          [-1, 512, 31, 31]           1,024\n",
            "           Conv2d-45          [-1, 512, 31, 31]         131,072\n",
            "      BatchNorm2d-46          [-1, 512, 31, 31]           1,024\n",
            "             ReLU-47          [-1, 512, 31, 31]               0\n",
            "       Bottleneck-48          [-1, 512, 31, 31]               0\n",
            "           Conv2d-49          [-1, 128, 31, 31]          65,536\n",
            "      BatchNorm2d-50          [-1, 128, 31, 31]             256\n",
            "             ReLU-51          [-1, 128, 31, 31]               0\n",
            "           Conv2d-52          [-1, 128, 31, 31]         147,456\n",
            "      BatchNorm2d-53          [-1, 128, 31, 31]             256\n",
            "             ReLU-54          [-1, 128, 31, 31]               0\n",
            "           Conv2d-55          [-1, 512, 31, 31]          65,536\n",
            "      BatchNorm2d-56          [-1, 512, 31, 31]           1,024\n",
            "             ReLU-57          [-1, 512, 31, 31]               0\n",
            "       Bottleneck-58          [-1, 512, 31, 31]               0\n",
            "           Conv2d-59          [-1, 128, 31, 31]          65,536\n",
            "      BatchNorm2d-60          [-1, 128, 31, 31]             256\n",
            "             ReLU-61          [-1, 128, 31, 31]               0\n",
            "           Conv2d-62          [-1, 128, 31, 31]         147,456\n",
            "      BatchNorm2d-63          [-1, 128, 31, 31]             256\n",
            "             ReLU-64          [-1, 128, 31, 31]               0\n",
            "           Conv2d-65          [-1, 512, 31, 31]          65,536\n",
            "      BatchNorm2d-66          [-1, 512, 31, 31]           1,024\n",
            "             ReLU-67          [-1, 512, 31, 31]               0\n",
            "       Bottleneck-68          [-1, 512, 31, 31]               0\n",
            "           Conv2d-69          [-1, 128, 31, 31]          65,536\n",
            "      BatchNorm2d-70          [-1, 128, 31, 31]             256\n",
            "             ReLU-71          [-1, 128, 31, 31]               0\n",
            "           Conv2d-72          [-1, 128, 31, 31]         147,456\n",
            "      BatchNorm2d-73          [-1, 128, 31, 31]             256\n",
            "             ReLU-74          [-1, 128, 31, 31]               0\n",
            "           Conv2d-75          [-1, 512, 31, 31]          65,536\n",
            "      BatchNorm2d-76          [-1, 512, 31, 31]           1,024\n",
            "             ReLU-77          [-1, 512, 31, 31]               0\n",
            "       Bottleneck-78          [-1, 512, 31, 31]               0\n",
            "           Conv2d-79          [-1, 128, 31, 31]          65,536\n",
            "      BatchNorm2d-80          [-1, 128, 31, 31]             256\n",
            "             ReLU-81          [-1, 128, 31, 31]               0\n",
            "           Conv2d-82          [-1, 128, 31, 31]         147,456\n",
            "      BatchNorm2d-83          [-1, 128, 31, 31]             256\n",
            "             ReLU-84          [-1, 128, 31, 31]               0\n",
            "           Conv2d-85          [-1, 512, 31, 31]          65,536\n",
            "      BatchNorm2d-86          [-1, 512, 31, 31]           1,024\n",
            "             ReLU-87          [-1, 512, 31, 31]               0\n",
            "       Bottleneck-88          [-1, 512, 31, 31]               0\n",
            "           Conv2d-89          [-1, 128, 31, 31]          65,536\n",
            "      BatchNorm2d-90          [-1, 128, 31, 31]             256\n",
            "             ReLU-91          [-1, 128, 31, 31]               0\n",
            "           Conv2d-92          [-1, 128, 31, 31]         147,456\n",
            "      BatchNorm2d-93          [-1, 128, 31, 31]             256\n",
            "             ReLU-94          [-1, 128, 31, 31]               0\n",
            "           Conv2d-95          [-1, 512, 31, 31]          65,536\n",
            "      BatchNorm2d-96          [-1, 512, 31, 31]           1,024\n",
            "             ReLU-97          [-1, 512, 31, 31]               0\n",
            "       Bottleneck-98          [-1, 512, 31, 31]               0\n",
            "           Conv2d-99          [-1, 128, 31, 31]          65,536\n",
            "     BatchNorm2d-100          [-1, 128, 31, 31]             256\n",
            "            ReLU-101          [-1, 128, 31, 31]               0\n",
            "          Conv2d-102          [-1, 128, 31, 31]         147,456\n",
            "     BatchNorm2d-103          [-1, 128, 31, 31]             256\n",
            "            ReLU-104          [-1, 128, 31, 31]               0\n",
            "          Conv2d-105          [-1, 512, 31, 31]          65,536\n",
            "     BatchNorm2d-106          [-1, 512, 31, 31]           1,024\n",
            "            ReLU-107          [-1, 512, 31, 31]               0\n",
            "      Bottleneck-108          [-1, 512, 31, 31]               0\n",
            "          Conv2d-109          [-1, 128, 31, 31]          65,536\n",
            "     BatchNorm2d-110          [-1, 128, 31, 31]             256\n",
            "            ReLU-111          [-1, 128, 31, 31]               0\n",
            "          Conv2d-112          [-1, 128, 31, 31]         147,456\n",
            "     BatchNorm2d-113          [-1, 128, 31, 31]             256\n",
            "            ReLU-114          [-1, 128, 31, 31]               0\n",
            "          Conv2d-115          [-1, 512, 31, 31]          65,536\n",
            "     BatchNorm2d-116          [-1, 512, 31, 31]           1,024\n",
            "            ReLU-117          [-1, 512, 31, 31]               0\n",
            "      Bottleneck-118          [-1, 512, 31, 31]               0\n",
            "          Conv2d-119          [-1, 256, 31, 31]         131,072\n",
            "     BatchNorm2d-120          [-1, 256, 31, 31]             512\n",
            "            ReLU-121          [-1, 256, 31, 31]               0\n",
            "          Conv2d-122          [-1, 256, 16, 16]         589,824\n",
            "     BatchNorm2d-123          [-1, 256, 16, 16]             512\n",
            "            ReLU-124          [-1, 256, 16, 16]               0\n",
            "          Conv2d-125         [-1, 1024, 16, 16]         262,144\n",
            "     BatchNorm2d-126         [-1, 1024, 16, 16]           2,048\n",
            "          Conv2d-127         [-1, 1024, 16, 16]         524,288\n",
            "     BatchNorm2d-128         [-1, 1024, 16, 16]           2,048\n",
            "            ReLU-129         [-1, 1024, 16, 16]               0\n",
            "      Bottleneck-130         [-1, 1024, 16, 16]               0\n",
            "          Conv2d-131          [-1, 256, 16, 16]         262,144\n",
            "     BatchNorm2d-132          [-1, 256, 16, 16]             512\n",
            "            ReLU-133          [-1, 256, 16, 16]               0\n",
            "          Conv2d-134          [-1, 256, 16, 16]         589,824\n",
            "     BatchNorm2d-135          [-1, 256, 16, 16]             512\n",
            "            ReLU-136          [-1, 256, 16, 16]               0\n",
            "          Conv2d-137         [-1, 1024, 16, 16]         262,144\n",
            "     BatchNorm2d-138         [-1, 1024, 16, 16]           2,048\n",
            "            ReLU-139         [-1, 1024, 16, 16]               0\n",
            "      Bottleneck-140         [-1, 1024, 16, 16]               0\n",
            "          Conv2d-141          [-1, 256, 16, 16]         262,144\n",
            "     BatchNorm2d-142          [-1, 256, 16, 16]             512\n",
            "            ReLU-143          [-1, 256, 16, 16]               0\n",
            "          Conv2d-144          [-1, 256, 16, 16]         589,824\n",
            "     BatchNorm2d-145          [-1, 256, 16, 16]             512\n",
            "            ReLU-146          [-1, 256, 16, 16]               0\n",
            "          Conv2d-147         [-1, 1024, 16, 16]         262,144\n",
            "     BatchNorm2d-148         [-1, 1024, 16, 16]           2,048\n",
            "            ReLU-149         [-1, 1024, 16, 16]               0\n",
            "      Bottleneck-150         [-1, 1024, 16, 16]               0\n",
            "          Conv2d-151          [-1, 256, 16, 16]         262,144\n",
            "     BatchNorm2d-152          [-1, 256, 16, 16]             512\n",
            "            ReLU-153          [-1, 256, 16, 16]               0\n",
            "          Conv2d-154          [-1, 256, 16, 16]         589,824\n",
            "     BatchNorm2d-155          [-1, 256, 16, 16]             512\n",
            "            ReLU-156          [-1, 256, 16, 16]               0\n",
            "          Conv2d-157         [-1, 1024, 16, 16]         262,144\n",
            "     BatchNorm2d-158         [-1, 1024, 16, 16]           2,048\n",
            "            ReLU-159         [-1, 1024, 16, 16]               0\n",
            "      Bottleneck-160         [-1, 1024, 16, 16]               0\n",
            "          Conv2d-161          [-1, 256, 16, 16]         262,144\n",
            "     BatchNorm2d-162          [-1, 256, 16, 16]             512\n",
            "            ReLU-163          [-1, 256, 16, 16]               0\n",
            "          Conv2d-164          [-1, 256, 16, 16]         589,824\n",
            "     BatchNorm2d-165          [-1, 256, 16, 16]             512\n",
            "            ReLU-166          [-1, 256, 16, 16]               0\n",
            "          Conv2d-167         [-1, 1024, 16, 16]         262,144\n",
            "     BatchNorm2d-168         [-1, 1024, 16, 16]           2,048\n",
            "            ReLU-169         [-1, 1024, 16, 16]               0\n",
            "      Bottleneck-170         [-1, 1024, 16, 16]               0\n",
            "          Conv2d-171          [-1, 256, 16, 16]         262,144\n",
            "     BatchNorm2d-172          [-1, 256, 16, 16]             512\n",
            "            ReLU-173          [-1, 256, 16, 16]               0\n",
            "          Conv2d-174          [-1, 256, 16, 16]         589,824\n",
            "     BatchNorm2d-175          [-1, 256, 16, 16]             512\n",
            "            ReLU-176          [-1, 256, 16, 16]               0\n",
            "          Conv2d-177         [-1, 1024, 16, 16]         262,144\n",
            "     BatchNorm2d-178         [-1, 1024, 16, 16]           2,048\n",
            "            ReLU-179         [-1, 1024, 16, 16]               0\n",
            "      Bottleneck-180         [-1, 1024, 16, 16]               0\n",
            "          Conv2d-181          [-1, 256, 16, 16]         262,144\n",
            "     BatchNorm2d-182          [-1, 256, 16, 16]             512\n",
            "            ReLU-183          [-1, 256, 16, 16]               0\n",
            "          Conv2d-184          [-1, 256, 16, 16]         589,824\n",
            "     BatchNorm2d-185          [-1, 256, 16, 16]             512\n",
            "            ReLU-186          [-1, 256, 16, 16]               0\n",
            "          Conv2d-187         [-1, 1024, 16, 16]         262,144\n",
            "     BatchNorm2d-188         [-1, 1024, 16, 16]           2,048\n",
            "            ReLU-189         [-1, 1024, 16, 16]               0\n",
            "      Bottleneck-190         [-1, 1024, 16, 16]               0\n",
            "          Conv2d-191          [-1, 256, 16, 16]         262,144\n",
            "     BatchNorm2d-192          [-1, 256, 16, 16]             512\n",
            "            ReLU-193          [-1, 256, 16, 16]               0\n",
            "          Conv2d-194          [-1, 256, 16, 16]         589,824\n",
            "     BatchNorm2d-195          [-1, 256, 16, 16]             512\n",
            "            ReLU-196          [-1, 256, 16, 16]               0\n",
            "          Conv2d-197         [-1, 1024, 16, 16]         262,144\n",
            "     BatchNorm2d-198         [-1, 1024, 16, 16]           2,048\n",
            "            ReLU-199         [-1, 1024, 16, 16]               0\n",
            "      Bottleneck-200         [-1, 1024, 16, 16]               0\n",
            "          Conv2d-201          [-1, 256, 16, 16]         262,144\n",
            "     BatchNorm2d-202          [-1, 256, 16, 16]             512\n",
            "            ReLU-203          [-1, 256, 16, 16]               0\n",
            "          Conv2d-204          [-1, 256, 16, 16]         589,824\n",
            "     BatchNorm2d-205          [-1, 256, 16, 16]             512\n",
            "            ReLU-206          [-1, 256, 16, 16]               0\n",
            "          Conv2d-207         [-1, 1024, 16, 16]         262,144\n",
            "     BatchNorm2d-208         [-1, 1024, 16, 16]           2,048\n",
            "            ReLU-209         [-1, 1024, 16, 16]               0\n",
            "      Bottleneck-210         [-1, 1024, 16, 16]               0\n",
            "          Conv2d-211          [-1, 256, 16, 16]         262,144\n",
            "     BatchNorm2d-212          [-1, 256, 16, 16]             512\n",
            "            ReLU-213          [-1, 256, 16, 16]               0\n",
            "          Conv2d-214          [-1, 256, 16, 16]         589,824\n",
            "     BatchNorm2d-215          [-1, 256, 16, 16]             512\n",
            "            ReLU-216          [-1, 256, 16, 16]               0\n",
            "          Conv2d-217         [-1, 1024, 16, 16]         262,144\n",
            "     BatchNorm2d-218         [-1, 1024, 16, 16]           2,048\n",
            "            ReLU-219         [-1, 1024, 16, 16]               0\n",
            "      Bottleneck-220         [-1, 1024, 16, 16]               0\n",
            "          Conv2d-221          [-1, 256, 16, 16]         262,144\n",
            "     BatchNorm2d-222          [-1, 256, 16, 16]             512\n",
            "            ReLU-223          [-1, 256, 16, 16]               0\n",
            "          Conv2d-224          [-1, 256, 16, 16]         589,824\n",
            "     BatchNorm2d-225          [-1, 256, 16, 16]             512\n",
            "            ReLU-226          [-1, 256, 16, 16]               0\n",
            "          Conv2d-227         [-1, 1024, 16, 16]         262,144\n",
            "     BatchNorm2d-228         [-1, 1024, 16, 16]           2,048\n",
            "            ReLU-229         [-1, 1024, 16, 16]               0\n",
            "      Bottleneck-230         [-1, 1024, 16, 16]               0\n",
            "          Conv2d-231          [-1, 256, 16, 16]         262,144\n",
            "     BatchNorm2d-232          [-1, 256, 16, 16]             512\n",
            "            ReLU-233          [-1, 256, 16, 16]               0\n",
            "          Conv2d-234          [-1, 256, 16, 16]         589,824\n",
            "     BatchNorm2d-235          [-1, 256, 16, 16]             512\n",
            "            ReLU-236          [-1, 256, 16, 16]               0\n",
            "          Conv2d-237         [-1, 1024, 16, 16]         262,144\n",
            "     BatchNorm2d-238         [-1, 1024, 16, 16]           2,048\n",
            "            ReLU-239         [-1, 1024, 16, 16]               0\n",
            "      Bottleneck-240         [-1, 1024, 16, 16]               0\n",
            "          Conv2d-241          [-1, 256, 16, 16]         262,144\n",
            "     BatchNorm2d-242          [-1, 256, 16, 16]             512\n",
            "            ReLU-243          [-1, 256, 16, 16]               0\n",
            "          Conv2d-244          [-1, 256, 16, 16]         589,824\n",
            "     BatchNorm2d-245          [-1, 256, 16, 16]             512\n",
            "            ReLU-246          [-1, 256, 16, 16]               0\n",
            "          Conv2d-247         [-1, 1024, 16, 16]         262,144\n",
            "     BatchNorm2d-248         [-1, 1024, 16, 16]           2,048\n",
            "            ReLU-249         [-1, 1024, 16, 16]               0\n",
            "      Bottleneck-250         [-1, 1024, 16, 16]               0\n",
            "          Conv2d-251          [-1, 256, 16, 16]         262,144\n",
            "     BatchNorm2d-252          [-1, 256, 16, 16]             512\n",
            "            ReLU-253          [-1, 256, 16, 16]               0\n",
            "          Conv2d-254          [-1, 256, 16, 16]         589,824\n",
            "     BatchNorm2d-255          [-1, 256, 16, 16]             512\n",
            "            ReLU-256          [-1, 256, 16, 16]               0\n",
            "          Conv2d-257         [-1, 1024, 16, 16]         262,144\n",
            "     BatchNorm2d-258         [-1, 1024, 16, 16]           2,048\n",
            "            ReLU-259         [-1, 1024, 16, 16]               0\n",
            "      Bottleneck-260         [-1, 1024, 16, 16]               0\n",
            "          Conv2d-261          [-1, 256, 16, 16]         262,144\n",
            "     BatchNorm2d-262          [-1, 256, 16, 16]             512\n",
            "            ReLU-263          [-1, 256, 16, 16]               0\n",
            "          Conv2d-264          [-1, 256, 16, 16]         589,824\n",
            "     BatchNorm2d-265          [-1, 256, 16, 16]             512\n",
            "            ReLU-266          [-1, 256, 16, 16]               0\n",
            "          Conv2d-267         [-1, 1024, 16, 16]         262,144\n",
            "     BatchNorm2d-268         [-1, 1024, 16, 16]           2,048\n",
            "            ReLU-269         [-1, 1024, 16, 16]               0\n",
            "      Bottleneck-270         [-1, 1024, 16, 16]               0\n",
            "          Conv2d-271          [-1, 256, 16, 16]         262,144\n",
            "     BatchNorm2d-272          [-1, 256, 16, 16]             512\n",
            "            ReLU-273          [-1, 256, 16, 16]               0\n",
            "          Conv2d-274          [-1, 256, 16, 16]         589,824\n",
            "     BatchNorm2d-275          [-1, 256, 16, 16]             512\n",
            "            ReLU-276          [-1, 256, 16, 16]               0\n",
            "          Conv2d-277         [-1, 1024, 16, 16]         262,144\n",
            "     BatchNorm2d-278         [-1, 1024, 16, 16]           2,048\n",
            "            ReLU-279         [-1, 1024, 16, 16]               0\n",
            "      Bottleneck-280         [-1, 1024, 16, 16]               0\n",
            "          Conv2d-281          [-1, 256, 16, 16]         262,144\n",
            "     BatchNorm2d-282          [-1, 256, 16, 16]             512\n",
            "            ReLU-283          [-1, 256, 16, 16]               0\n",
            "          Conv2d-284          [-1, 256, 16, 16]         589,824\n",
            "     BatchNorm2d-285          [-1, 256, 16, 16]             512\n",
            "            ReLU-286          [-1, 256, 16, 16]               0\n",
            "          Conv2d-287         [-1, 1024, 16, 16]         262,144\n",
            "     BatchNorm2d-288         [-1, 1024, 16, 16]           2,048\n",
            "            ReLU-289         [-1, 1024, 16, 16]               0\n",
            "      Bottleneck-290         [-1, 1024, 16, 16]               0\n",
            "          Conv2d-291          [-1, 256, 16, 16]         262,144\n",
            "     BatchNorm2d-292          [-1, 256, 16, 16]             512\n",
            "            ReLU-293          [-1, 256, 16, 16]               0\n",
            "          Conv2d-294          [-1, 256, 16, 16]         589,824\n",
            "     BatchNorm2d-295          [-1, 256, 16, 16]             512\n",
            "            ReLU-296          [-1, 256, 16, 16]               0\n",
            "          Conv2d-297         [-1, 1024, 16, 16]         262,144\n",
            "     BatchNorm2d-298         [-1, 1024, 16, 16]           2,048\n",
            "            ReLU-299         [-1, 1024, 16, 16]               0\n",
            "      Bottleneck-300         [-1, 1024, 16, 16]               0\n",
            "          Conv2d-301          [-1, 256, 16, 16]         262,144\n",
            "     BatchNorm2d-302          [-1, 256, 16, 16]             512\n",
            "            ReLU-303          [-1, 256, 16, 16]               0\n",
            "          Conv2d-304          [-1, 256, 16, 16]         589,824\n",
            "     BatchNorm2d-305          [-1, 256, 16, 16]             512\n",
            "            ReLU-306          [-1, 256, 16, 16]               0\n",
            "          Conv2d-307         [-1, 1024, 16, 16]         262,144\n",
            "     BatchNorm2d-308         [-1, 1024, 16, 16]           2,048\n",
            "            ReLU-309         [-1, 1024, 16, 16]               0\n",
            "      Bottleneck-310         [-1, 1024, 16, 16]               0\n",
            "          Conv2d-311          [-1, 256, 16, 16]         262,144\n",
            "     BatchNorm2d-312          [-1, 256, 16, 16]             512\n",
            "            ReLU-313          [-1, 256, 16, 16]               0\n",
            "          Conv2d-314          [-1, 256, 16, 16]         589,824\n",
            "     BatchNorm2d-315          [-1, 256, 16, 16]             512\n",
            "            ReLU-316          [-1, 256, 16, 16]               0\n",
            "          Conv2d-317         [-1, 1024, 16, 16]         262,144\n",
            "     BatchNorm2d-318         [-1, 1024, 16, 16]           2,048\n",
            "            ReLU-319         [-1, 1024, 16, 16]               0\n",
            "      Bottleneck-320         [-1, 1024, 16, 16]               0\n",
            "          Conv2d-321          [-1, 256, 16, 16]         262,144\n",
            "     BatchNorm2d-322          [-1, 256, 16, 16]             512\n",
            "            ReLU-323          [-1, 256, 16, 16]               0\n",
            "          Conv2d-324          [-1, 256, 16, 16]         589,824\n",
            "     BatchNorm2d-325          [-1, 256, 16, 16]             512\n",
            "            ReLU-326          [-1, 256, 16, 16]               0\n",
            "          Conv2d-327         [-1, 1024, 16, 16]         262,144\n",
            "     BatchNorm2d-328         [-1, 1024, 16, 16]           2,048\n",
            "            ReLU-329         [-1, 1024, 16, 16]               0\n",
            "      Bottleneck-330         [-1, 1024, 16, 16]               0\n",
            "          Conv2d-331          [-1, 256, 16, 16]         262,144\n",
            "     BatchNorm2d-332          [-1, 256, 16, 16]             512\n",
            "            ReLU-333          [-1, 256, 16, 16]               0\n",
            "          Conv2d-334          [-1, 256, 16, 16]         589,824\n",
            "     BatchNorm2d-335          [-1, 256, 16, 16]             512\n",
            "            ReLU-336          [-1, 256, 16, 16]               0\n",
            "          Conv2d-337         [-1, 1024, 16, 16]         262,144\n",
            "     BatchNorm2d-338         [-1, 1024, 16, 16]           2,048\n",
            "            ReLU-339         [-1, 1024, 16, 16]               0\n",
            "      Bottleneck-340         [-1, 1024, 16, 16]               0\n",
            "          Conv2d-341          [-1, 256, 16, 16]         262,144\n",
            "     BatchNorm2d-342          [-1, 256, 16, 16]             512\n",
            "            ReLU-343          [-1, 256, 16, 16]               0\n",
            "          Conv2d-344          [-1, 256, 16, 16]         589,824\n",
            "     BatchNorm2d-345          [-1, 256, 16, 16]             512\n",
            "            ReLU-346          [-1, 256, 16, 16]               0\n",
            "          Conv2d-347         [-1, 1024, 16, 16]         262,144\n",
            "     BatchNorm2d-348         [-1, 1024, 16, 16]           2,048\n",
            "            ReLU-349         [-1, 1024, 16, 16]               0\n",
            "      Bottleneck-350         [-1, 1024, 16, 16]               0\n",
            "          Conv2d-351          [-1, 256, 16, 16]         262,144\n",
            "     BatchNorm2d-352          [-1, 256, 16, 16]             512\n",
            "            ReLU-353          [-1, 256, 16, 16]               0\n",
            "          Conv2d-354          [-1, 256, 16, 16]         589,824\n",
            "     BatchNorm2d-355          [-1, 256, 16, 16]             512\n",
            "            ReLU-356          [-1, 256, 16, 16]               0\n",
            "          Conv2d-357         [-1, 1024, 16, 16]         262,144\n",
            "     BatchNorm2d-358         [-1, 1024, 16, 16]           2,048\n",
            "            ReLU-359         [-1, 1024, 16, 16]               0\n",
            "      Bottleneck-360         [-1, 1024, 16, 16]               0\n",
            "          Conv2d-361          [-1, 256, 16, 16]         262,144\n",
            "     BatchNorm2d-362          [-1, 256, 16, 16]             512\n",
            "            ReLU-363          [-1, 256, 16, 16]               0\n",
            "          Conv2d-364          [-1, 256, 16, 16]         589,824\n",
            "     BatchNorm2d-365          [-1, 256, 16, 16]             512\n",
            "            ReLU-366          [-1, 256, 16, 16]               0\n",
            "          Conv2d-367         [-1, 1024, 16, 16]         262,144\n",
            "     BatchNorm2d-368         [-1, 1024, 16, 16]           2,048\n",
            "            ReLU-369         [-1, 1024, 16, 16]               0\n",
            "      Bottleneck-370         [-1, 1024, 16, 16]               0\n",
            "          Conv2d-371          [-1, 256, 16, 16]         262,144\n",
            "     BatchNorm2d-372          [-1, 256, 16, 16]             512\n",
            "            ReLU-373          [-1, 256, 16, 16]               0\n",
            "          Conv2d-374          [-1, 256, 16, 16]         589,824\n",
            "     BatchNorm2d-375          [-1, 256, 16, 16]             512\n",
            "            ReLU-376          [-1, 256, 16, 16]               0\n",
            "          Conv2d-377         [-1, 1024, 16, 16]         262,144\n",
            "     BatchNorm2d-378         [-1, 1024, 16, 16]           2,048\n",
            "            ReLU-379         [-1, 1024, 16, 16]               0\n",
            "      Bottleneck-380         [-1, 1024, 16, 16]               0\n",
            "          Conv2d-381          [-1, 256, 16, 16]         262,144\n",
            "     BatchNorm2d-382          [-1, 256, 16, 16]             512\n",
            "            ReLU-383          [-1, 256, 16, 16]               0\n",
            "          Conv2d-384          [-1, 256, 16, 16]         589,824\n",
            "     BatchNorm2d-385          [-1, 256, 16, 16]             512\n",
            "            ReLU-386          [-1, 256, 16, 16]               0\n",
            "          Conv2d-387         [-1, 1024, 16, 16]         262,144\n",
            "     BatchNorm2d-388         [-1, 1024, 16, 16]           2,048\n",
            "            ReLU-389         [-1, 1024, 16, 16]               0\n",
            "      Bottleneck-390         [-1, 1024, 16, 16]               0\n",
            "          Conv2d-391          [-1, 256, 16, 16]         262,144\n",
            "     BatchNorm2d-392          [-1, 256, 16, 16]             512\n",
            "            ReLU-393          [-1, 256, 16, 16]               0\n",
            "          Conv2d-394          [-1, 256, 16, 16]         589,824\n",
            "     BatchNorm2d-395          [-1, 256, 16, 16]             512\n",
            "            ReLU-396          [-1, 256, 16, 16]               0\n",
            "          Conv2d-397         [-1, 1024, 16, 16]         262,144\n",
            "     BatchNorm2d-398         [-1, 1024, 16, 16]           2,048\n",
            "            ReLU-399         [-1, 1024, 16, 16]               0\n",
            "      Bottleneck-400         [-1, 1024, 16, 16]               0\n",
            "          Conv2d-401          [-1, 256, 16, 16]         262,144\n",
            "     BatchNorm2d-402          [-1, 256, 16, 16]             512\n",
            "            ReLU-403          [-1, 256, 16, 16]               0\n",
            "          Conv2d-404          [-1, 256, 16, 16]         589,824\n",
            "     BatchNorm2d-405          [-1, 256, 16, 16]             512\n",
            "            ReLU-406          [-1, 256, 16, 16]               0\n",
            "          Conv2d-407         [-1, 1024, 16, 16]         262,144\n",
            "     BatchNorm2d-408         [-1, 1024, 16, 16]           2,048\n",
            "            ReLU-409         [-1, 1024, 16, 16]               0\n",
            "      Bottleneck-410         [-1, 1024, 16, 16]               0\n",
            "          Conv2d-411          [-1, 256, 16, 16]         262,144\n",
            "     BatchNorm2d-412          [-1, 256, 16, 16]             512\n",
            "            ReLU-413          [-1, 256, 16, 16]               0\n",
            "          Conv2d-414          [-1, 256, 16, 16]         589,824\n",
            "     BatchNorm2d-415          [-1, 256, 16, 16]             512\n",
            "            ReLU-416          [-1, 256, 16, 16]               0\n",
            "          Conv2d-417         [-1, 1024, 16, 16]         262,144\n",
            "     BatchNorm2d-418         [-1, 1024, 16, 16]           2,048\n",
            "            ReLU-419         [-1, 1024, 16, 16]               0\n",
            "      Bottleneck-420         [-1, 1024, 16, 16]               0\n",
            "          Conv2d-421          [-1, 256, 16, 16]         262,144\n",
            "     BatchNorm2d-422          [-1, 256, 16, 16]             512\n",
            "            ReLU-423          [-1, 256, 16, 16]               0\n",
            "          Conv2d-424          [-1, 256, 16, 16]         589,824\n",
            "     BatchNorm2d-425          [-1, 256, 16, 16]             512\n",
            "            ReLU-426          [-1, 256, 16, 16]               0\n",
            "          Conv2d-427         [-1, 1024, 16, 16]         262,144\n",
            "     BatchNorm2d-428         [-1, 1024, 16, 16]           2,048\n",
            "            ReLU-429         [-1, 1024, 16, 16]               0\n",
            "      Bottleneck-430         [-1, 1024, 16, 16]               0\n",
            "          Conv2d-431          [-1, 256, 16, 16]         262,144\n",
            "     BatchNorm2d-432          [-1, 256, 16, 16]             512\n",
            "            ReLU-433          [-1, 256, 16, 16]               0\n",
            "          Conv2d-434          [-1, 256, 16, 16]         589,824\n",
            "     BatchNorm2d-435          [-1, 256, 16, 16]             512\n",
            "            ReLU-436          [-1, 256, 16, 16]               0\n",
            "          Conv2d-437         [-1, 1024, 16, 16]         262,144\n",
            "     BatchNorm2d-438         [-1, 1024, 16, 16]           2,048\n",
            "            ReLU-439         [-1, 1024, 16, 16]               0\n",
            "      Bottleneck-440         [-1, 1024, 16, 16]               0\n",
            "          Conv2d-441          [-1, 256, 16, 16]         262,144\n",
            "     BatchNorm2d-442          [-1, 256, 16, 16]             512\n",
            "            ReLU-443          [-1, 256, 16, 16]               0\n",
            "          Conv2d-444          [-1, 256, 16, 16]         589,824\n",
            "     BatchNorm2d-445          [-1, 256, 16, 16]             512\n",
            "            ReLU-446          [-1, 256, 16, 16]               0\n",
            "          Conv2d-447         [-1, 1024, 16, 16]         262,144\n",
            "     BatchNorm2d-448         [-1, 1024, 16, 16]           2,048\n",
            "            ReLU-449         [-1, 1024, 16, 16]               0\n",
            "      Bottleneck-450         [-1, 1024, 16, 16]               0\n",
            "          Conv2d-451          [-1, 256, 16, 16]         262,144\n",
            "     BatchNorm2d-452          [-1, 256, 16, 16]             512\n",
            "            ReLU-453          [-1, 256, 16, 16]               0\n",
            "          Conv2d-454          [-1, 256, 16, 16]         589,824\n",
            "     BatchNorm2d-455          [-1, 256, 16, 16]             512\n",
            "            ReLU-456          [-1, 256, 16, 16]               0\n",
            "          Conv2d-457         [-1, 1024, 16, 16]         262,144\n",
            "     BatchNorm2d-458         [-1, 1024, 16, 16]           2,048\n",
            "            ReLU-459         [-1, 1024, 16, 16]               0\n",
            "      Bottleneck-460         [-1, 1024, 16, 16]               0\n",
            "          Conv2d-461          [-1, 256, 16, 16]         262,144\n",
            "     BatchNorm2d-462          [-1, 256, 16, 16]             512\n",
            "            ReLU-463          [-1, 256, 16, 16]               0\n",
            "          Conv2d-464          [-1, 256, 16, 16]         589,824\n",
            "     BatchNorm2d-465          [-1, 256, 16, 16]             512\n",
            "            ReLU-466          [-1, 256, 16, 16]               0\n",
            "          Conv2d-467         [-1, 1024, 16, 16]         262,144\n",
            "     BatchNorm2d-468         [-1, 1024, 16, 16]           2,048\n",
            "            ReLU-469         [-1, 1024, 16, 16]               0\n",
            "      Bottleneck-470         [-1, 1024, 16, 16]               0\n",
            "          Conv2d-471          [-1, 256, 16, 16]         262,144\n",
            "     BatchNorm2d-472          [-1, 256, 16, 16]             512\n",
            "            ReLU-473          [-1, 256, 16, 16]               0\n",
            "          Conv2d-474          [-1, 256, 16, 16]         589,824\n",
            "     BatchNorm2d-475          [-1, 256, 16, 16]             512\n",
            "            ReLU-476          [-1, 256, 16, 16]               0\n",
            "          Conv2d-477         [-1, 1024, 16, 16]         262,144\n",
            "     BatchNorm2d-478         [-1, 1024, 16, 16]           2,048\n",
            "            ReLU-479         [-1, 1024, 16, 16]               0\n",
            "      Bottleneck-480         [-1, 1024, 16, 16]               0\n",
            "          Conv2d-481          [-1, 512, 16, 16]         524,288\n",
            "     BatchNorm2d-482          [-1, 512, 16, 16]           1,024\n",
            "            ReLU-483          [-1, 512, 16, 16]               0\n",
            "          Conv2d-484            [-1, 512, 8, 8]       2,359,296\n",
            "     BatchNorm2d-485            [-1, 512, 8, 8]           1,024\n",
            "            ReLU-486            [-1, 512, 8, 8]               0\n",
            "          Conv2d-487           [-1, 2048, 8, 8]       1,048,576\n",
            "     BatchNorm2d-488           [-1, 2048, 8, 8]           4,096\n",
            "          Conv2d-489           [-1, 2048, 8, 8]       2,097,152\n",
            "     BatchNorm2d-490           [-1, 2048, 8, 8]           4,096\n",
            "            ReLU-491           [-1, 2048, 8, 8]               0\n",
            "      Bottleneck-492           [-1, 2048, 8, 8]               0\n",
            "          Conv2d-493            [-1, 512, 8, 8]       1,048,576\n",
            "     BatchNorm2d-494            [-1, 512, 8, 8]           1,024\n",
            "            ReLU-495            [-1, 512, 8, 8]               0\n",
            "          Conv2d-496            [-1, 512, 8, 8]       2,359,296\n",
            "     BatchNorm2d-497            [-1, 512, 8, 8]           1,024\n",
            "            ReLU-498            [-1, 512, 8, 8]               0\n",
            "          Conv2d-499           [-1, 2048, 8, 8]       1,048,576\n",
            "     BatchNorm2d-500           [-1, 2048, 8, 8]           4,096\n",
            "            ReLU-501           [-1, 2048, 8, 8]               0\n",
            "      Bottleneck-502           [-1, 2048, 8, 8]               0\n",
            "          Conv2d-503            [-1, 512, 8, 8]       1,048,576\n",
            "     BatchNorm2d-504            [-1, 512, 8, 8]           1,024\n",
            "            ReLU-505            [-1, 512, 8, 8]               0\n",
            "          Conv2d-506            [-1, 512, 8, 8]       2,359,296\n",
            "     BatchNorm2d-507            [-1, 512, 8, 8]           1,024\n",
            "            ReLU-508            [-1, 512, 8, 8]               0\n",
            "          Conv2d-509           [-1, 2048, 8, 8]       1,048,576\n",
            "     BatchNorm2d-510           [-1, 2048, 8, 8]           4,096\n",
            "            ReLU-511           [-1, 2048, 8, 8]               0\n",
            "      Bottleneck-512           [-1, 2048, 8, 8]               0\n",
            "AdaptiveAvgPool2d-513           [-1, 2048, 1, 1]               0\n",
            "          Linear-514                 [-1, 1000]       2,049,000\n",
            "================================================================\n",
            "Total params: 60,192,808\n",
            "Trainable params: 60,192,808\n",
            "Non-trainable params: 0\n",
            "----------------------------------------------------------------\n",
            "Input size (MB): 0.68\n",
            "Forward/backward pass size (MB): 763.74\n",
            "Params size (MB): 229.62\n",
            "Estimated Total Size (MB): 994.04\n",
            "----------------------------------------------------------------\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tq_RI9wCIeBH"
      },
      "source": [
        " t = torch.tensor([[[1, 2],\r\n",
        "                       [3, 4]],\r\n",
        "                      [[5, 6],\r\n",
        "                       [7, 8]]], dtype=float)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8JAghxsFZ4dd",
        "outputId": "4c700e8b-20e3-43bc-de99-17677ec0db05"
      },
      "source": [
        "t.size()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([2, 2, 2])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 36
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6BDP-I8pZ5kW",
        "outputId": "564c7aca-e070-471d-e645-6807b9df6b5b"
      },
      "source": [
        "a = nn.AdaptiveAvgPool2d(7)\r\n",
        "a(t)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[[1.0000, 1.0000, 1.0000, 1.5000, 2.0000, 2.0000, 2.0000],\n",
              "         [1.0000, 1.0000, 1.0000, 1.5000, 2.0000, 2.0000, 2.0000],\n",
              "         [1.0000, 1.0000, 1.0000, 1.5000, 2.0000, 2.0000, 2.0000],\n",
              "         [2.0000, 2.0000, 2.0000, 2.5000, 3.0000, 3.0000, 3.0000],\n",
              "         [3.0000, 3.0000, 3.0000, 3.5000, 4.0000, 4.0000, 4.0000],\n",
              "         [3.0000, 3.0000, 3.0000, 3.5000, 4.0000, 4.0000, 4.0000],\n",
              "         [3.0000, 3.0000, 3.0000, 3.5000, 4.0000, 4.0000, 4.0000]],\n",
              "\n",
              "        [[5.0000, 5.0000, 5.0000, 5.5000, 6.0000, 6.0000, 6.0000],\n",
              "         [5.0000, 5.0000, 5.0000, 5.5000, 6.0000, 6.0000, 6.0000],\n",
              "         [5.0000, 5.0000, 5.0000, 5.5000, 6.0000, 6.0000, 6.0000],\n",
              "         [6.0000, 6.0000, 6.0000, 6.5000, 7.0000, 7.0000, 7.0000],\n",
              "         [7.0000, 7.0000, 7.0000, 7.5000, 8.0000, 8.0000, 8.0000],\n",
              "         [7.0000, 7.0000, 7.0000, 7.5000, 8.0000, 8.0000, 8.0000],\n",
              "         [7.0000, 7.0000, 7.0000, 7.5000, 8.0000, 8.0000, 8.0000]]],\n",
              "       dtype=torch.float64)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 37
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TiIOhUxvaE77"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}